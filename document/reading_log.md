## Jan. 27
### Dobriban, 2019

* First to be able to distinguish performance of different sketching matrices.
* Considers various loss functions.
* Note: possible connections to factor rotations? See uniform sampling section.

## Jan. 26
### Pilanci, 2016

* IHS introduced with discussion of least squares problems with convex constraints.
* Original motivation is to address sub-optimality (w.r.t. solution approximation) of classical least squares sketching.
* Sketch dimension per iteration only needs to be proportional to dimension of optimal solution.
* log(1/epsilon) iterations for epsilon-accurate solution.
* Ideas: regularized regression, convex Lp-norm regression problems.

## Jan. 23
### Couillet, 2011

* More comprehensive introduction to random matrix theory.

## Jan. 19-22
### Lacotte, 2020

* The convergence rate results are derived based on the limiting spectral distributions, which are obtained by applying results from random matrix theory/free probability.

### Xia, 2019

* Light introduction and decent starting point to random matrix theory.
* Note: possible connections to factor rotations? See cumulants section.